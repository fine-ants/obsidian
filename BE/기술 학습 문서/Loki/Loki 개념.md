
- [[#Grafana Loki란 무엇인가?|Grafana Loki란 무엇인가?]]
		- [[#Loki가 메타데이터만 인덱싱하는 이유|Loki가 메타데이터만 인덱싱하는 이유]]
		- [[#데이터 읽기/쓰기 흐름 과정|데이터 읽기/쓰기 흐름 과정]]
		- [[#WAL(Write Ahead Log)|WAL(Write Ahead Log)]]
- [[#References|References]]


## Grafana Loki란 무엇인가?
Grafana Loki는 Prometheus에서 영감을 받은 로그 집계 시스템으로, 로깅 및 이벤트 데이터를 수집하고, 저장하고 검색하기 위한 오픈소스 플랫폼입니다.

Loki는 로그 전체 텍스트가 아닌 메타데이터(metadata)만 인덱싱(Indexing)하는 방식을 취합니다. 다음 그림을 보면 Timestamp와 Label 부분만 인덱싱하는 작업을 수행하고, 로깅의 내용 부분은 인덱싱하지 않습니다. 
![[Pasted image 20250210140630.png]]

#### Loki가 메타데이터만 인덱싱하는 이유
Loki가 로그 전체 텍스트가 아닌 메타 데이터만 인덱싱하는 방식을 취하는 이유는 다음과 같습니다.
- 인덱스 크기 최소화
	- 로그 데이터를 완전히 인덱싱하려면 로그 전체 텍스트를 저장해야 하는데, 이는 매우 많은 저장 공간이 필요합니다.
	- 로그 텍스트가 길면 길수록 비효율적이고 비용이 많이 소요됩니다.
	- 대신에 메타 데이터(로그 레벨, 서비스 이름, 파일 이름, 타임스탬프, 라벨 등)만 인덱싱하면 **인덱스 크기가 줄어들어서 빠르게 조회할 수 있고, 저장 비용도 감소**합니다.
- 빠른 검색 및 쿼리 성능 향상
	- Loki는 시간 기반의 로그 쿼리를 자주 실행합니다. 예를 들어, 특정 시간 범위 이내의 로그를 검색하는 경우, 메타 데이터를 인덱싱함으로써 쿼리를 효율적으로 처리할 수 있습니다.
	- 예를 들어 job, instance, level, filename과 같은 메타 데이터를 기준으로 로그를 빠르게 필터링할 수 있습니다.
- 저장 비용 절감
	- 로그 전체 텍스트를 저장하면 저장 비용이 증가됩니다. 하지만 메타 데이터만 인덱싱하면 데이터 크기를 줄일수 있습니다. 이는 비용 절감으로 이어집니다.
	- 실제 로그 메시지 본문은 청크(chunk) 데이터 단위로 저장되며, 검색 시에는 메타 데이터만 참조하여 필요한 데이터를 빠르게 찾습니다. 로그 메시지 본문은 필요할때만 불러오고 검색 효율성을 증가시킵니다.
- 확장성
	- 로그의 양이 급증할 수 있는 환경에서 메타 데이터만 인덱싱하는 방식은 **시스템의 확장성을 높여줍니다.**
	- 전체 로그 텍스트를 인덱싱하면 시스템이 성능 문제를 일으킬 수 있지만, 메타 데이터만 인덱싱하면 더 많은 데이터를 처리할 수 있습니다.

Grafana Loki는 다음과 같이 작동합니다.
![[Pasted image 20250210143724.png]]
Loki를 위해 만들어진 로그 수집 도구인 Promtail을 통해서 로그를 수집하고 Loki에 저장합니다. 이후 Grafana에서 LogQL이라는 쿼리 언어를 통해서 로그를 검색합니다. 또한 경고 규칙을 설정하여 Prometheus AlertManager로 경고를 보낼수 있습니다.

다음은 Grafana Loki의 주요 구성 요소입니다.
![[Pasted image 20250210144024.png]]
다음은 Grafana Loki 주요 구성 요소의 설명입니다.
- Distributor
	- 클라이언트로부터 수신한 로그 데이터를 검증 후에 Ingester에게 전달하는 역할을 수행합니다.
- Ingester
	- Distributor로부터 받은 로그 데이터를 메모리에 압축하여 chunks 단위로 저장하고, 일정 시간 후에 장기 저장소(DynamoDB, S3, Cassandra 등)에 기록합니다.
- Querier
	- Ingester의 인메모리(in-memory) 데이터를 쿼리한 후에 장기 저장소(S3)에서 쿼리 로그를 가져와 Query-Frontend에게 데이터를 반환합니다. Ingester에서 복제 데이터를 가져올수 있기 때문에 내부적으로 중복을 제거합니다.
- Query-Frontend
	- 실제 쿼리 실행에 필요한 Querier의 역할을 보조하며 읽기 경로를 가속화합니다. Query Frontend는 내부적으로 쿼리를 조정하고 큐에 보관합니다.
- Compactor
	- chunk 보관 주기를 관리하고(retention), 테이블을 단일 인덱스 파일로 압축합니다.
	- Compactor를 통한 보존은 boltdb-shipper 또는 tsdb store에서만 지원됩니다.
		- Loki 2.8 부터는 tsdb store 사용 권장, boltdb-shipper보다 효율적이고 빠르며 확장이 뛰어납니다.
- Ruler
	- 사용자가 정의한 경고 규칙 기반으로 경고를 발생시키는 등 로그 데이터에 관한 경고를 관리합니다.

#### 데이터 읽기/쓰기 흐름 과정
**읽기 흐름 과정**
1. Read 요청할때 Querier에서 해당 요청을 수신합니다.
2. Querier는 Ingester의 인메모리(in-memory)를 조회합니다.
3. Ingester에서 캐시된 데이터가 있는 경우 Querier에게 반환하고, 캐시된 데이터가 없다면 장기 저장소(S3)에서 데이터를 조회합니다.
4. Querier는 수신된 데이터가 중복됬는지 확인한 후에 중복 제거를 진행하고 로그를 제공합니다.
	- 수신된 데이터가 중복되었다는 의미는 같은 로그 데이터가 여러번 수신되었다는 의미입니다.
	- 중복 데이터는 다중 Ingester에서 동일한 로그를 수신하거나 다중 소스에서 동일한 로그를 수집할때 중복된 데이터가 발생합니다.

쓰기 흐름 과정
1. Distributor가 데이터를 수신합니다.
2. 수신된 데이터는 해시 과정을 수행합니다.
3. Distributor는 해시된 데이터를 Ingester에게 전달합니다.
4. Ingester는 데이터에 대해 Chunk 데이터 단위로 생성하고 저장합니다.
5. Distributor는 데이터에 대한 저장 완료 여부를 성공 코드로 응답합니다.

#### WAL(Write Ahead Log)
Loki에서는 WAL(Write Ahead Log) 기능을 사용합니다. WAL 기능을 통해서 다음과 같은 상황을 방지합니다.
1. 데이터(chunk)가 Ingester로 들어오면, 먼저 이 데이터를 메모리 적재 및 WAL 디렉토리에 기록합니다. WAL은 로컬 파일 시스템에 저장됩니다.
2. 예기치 않은 장애로 인하여 로키 프로세스가 갑자기 중단되거나 다운되면, 메모리에 있는 데이터가 손실됩니다.
3. 장애가 복구되어 로키 프로세스가 다시 시작되면, WAL에 저장된 데이터를 읽어와서 메모리에 적재하여 장애 전의 상태로 복구합니다.

이와 같이 WAL 기능을 이용하면 인메모리에 데이터를 저장하기 전에 WAL 디렉토리에 데이터를 미리 저장함으로써 데이터 손실을 방지합니다. 즉, **WAL 기능은 로키 프로세스 중단으로 인한 데이터 손실을 방지하는 기능**입니다.

## References
- https://wlsdn3004.tistory.com/48