
## The task of collecting logs
어떤 로깅 시스템을 통합하기 위해 시도하기 전에 여러분들 스스로 다음 4가지 질문에 답해보세요.
1. 나는 지금 어떻게 로그를 모으고 있나요?
2. 추후에 로그들을 쉽게 처리하기 위해서 로그들에서 올바른 메타데이터를 어떻게 추출하는가?
3. 나는 로그 데이터를 빠르게 저장하고 탐색할 수 있도록 어떻게 데이터를 저장하는가?
4. 나는 어떻게 로그를 쿼리하는가?

모든 시스템, 예를 들어 syslog, Elasticsearch, ClickHouse 기반 시스템, 심지어 Grafana Loki 자체도 이 질문들에 대해서는 서로 다르게 응답할 것입니다.

그래서 우리가 아키텍처에 대해서 의논할때, Grafana Loki가 Elasticsearch와 개념적으로 어떻게 다른지, 그리고 로그 저장비용 측면에서 Loki가 왜 좋은지 이야기 할것입니다.

로그 컬렉션 파이프라인은 일반적으로 다음과 같이 간단하고 직관적입니다.
![[Pasted image 20250210152916.png]]

우리는 다양한 데이터 소스들에서 로그들을 얻습니다. 대표적으로 쿠버네티스 클러스터, 가상 머신, 도커 컨테이너 등이 있습니다. 이 데이터 소스들은 로그들을 수집하고, 처리하고 단계를 필터링을 수행합니다.
그리고 나서 데이터 소스들은 여러분들이 지정한 저장소에 데이터들을 저장합니다. 예를 들어 ClickHouse, S3, Grafana Loki와 같은 저장소가 있습니다. 하지만 데이터를 서로 다른 쪽에서 가져오는 모든 사용자가 각기 다른 액션 스크립트를 가질수 있다는 점을 유의해야 합니다.  예를 들어 1년 이나 10분 이내의 데이터를 가져올수 있습니다.

## Ways to launch Loki
Loki를 실행하는 3가지 방법이 있습니다. 이 방법들에는 대체로 규모에서 차이가 있습니다.

### Single-binary
![[Pasted image 20250210153716.png]]

이 방법은 주요한 로키 튜토리얼에서 가장 많이 사용하는 방법입니다. 로직은 다음과 같습니다. 우리는 스토리지와 연결합니다.

스토리지의 역할은 파일 시스템과 S3 버킷 모두에서 수행됩니다. 하지만 여기서는 중요치 않습니다. 이 접근은 장점들을 가지고 있습니다. 예를 들어 런칭이 쉽습니다. 여러분들은 최소한의 설정만 하면 됩니다. 단점은 낮은 **내결함성**입니다. 만약 머신에 장애가 발생하면 로그가 기록되지 않습니다.

위와 같은 상황은 다음과 같이 개선할 수 있습니다.
- 서로 다른 2개의 가상 머신에서 같은 설정을 가진 로키 프로세스를 실행시킵니다.
- memberlist 영역을 사용하여 클러스터로 결합시킵니다.
- 스토리지 전면에 Nginx나 HAP